# An unique identifier for the head node and workers of this cluster.
cluster_name: llm-batch-inference

max_workers: 5

# Cloud-provider specific configuration.
provider:
    type: aws
    region: us-west-2
    # In case you need to specify a pre-generated EC2 SSH key.
    # In this case, you need to download the key from the EC2 console,
    # move it to your ~/.ssh/ directory and grant the correct permissions like `chmod 400 ~/.ssh/llm-blogpost-test-key.pem`
    # Then, uncomment the below lines and replace `key_name` with the name of your key:
    # key_pair:
    #   key_name: llm-blogpost-test-key

# List of shell commands to run to set up nodes.
setup_commands:
    - >-
        (stat $HOME/anaconda3/envs/tensorflow2_p38/ &> /dev/null &&
        echo 'export PATH="$HOME/anaconda3/envs/tensorflow2_p38/bin:$PATH"' >> ~/.bashrc) || true
    - which ray || pip install -U "ray[default]"

available_node_types:
  ray.head.default:
      resources: {"CPU": 48, "GPU": 4}
      node_config:
        InstanceType: g4dn.12xlarge
        BlockDeviceMappings:
            - DeviceName: /dev/sda1
              Ebs:
                  VolumeSize: 200
  ray.worker.default:
      node_config:
        InstanceType: g4dn.12xlarge
        BlockDeviceMappings:
            - DeviceName: /dev/sda1
              Ebs:
                  VolumeSize: 200
      resources: {"CPU": 48, "GPU": 4}
      min_workers: 4
      max_workers: 4
